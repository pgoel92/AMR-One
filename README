Contents : 

README
corp : JAMR aligner output corpus file 
span : JAMR aligner output span file
corp-span : merged corpus and span file
corp-span-perfect : merged file with only perfectly aligned sentences
corp-span-imperfect : merged file with only imperfectly aligned sentences
run.sh : script that runs the JAMR aligner on the test data from AMR public release 1.3
mod-out.py : creates corp-span after taking as input files corp and span
freq_unaligned : Lists all the frequently unaligned concepts with their counts
cooccuring_words : Lists for each frequently unaligned concept, all the words it frequently occurs with
cooccuring_words_two : Lists the most frequently occurring (unaligned concept,word) pairs

I finished watching videos for and summarizing Week 2 of the Coursera course NLP. It was about the tagging problem and HMMs. I also went through the Bolinas tutorial, the AMR paper and the AMR guidelines, not very thoroughly though. On Sunday, after beating away a migraine, I sat all day to write code for compiling statistics as discussed in the meeting on Monday. I polished off the final code mod_out.py before the meeting to ensure it ran smoothly in case the need arose to demonstrate.

I could not complete the second task for the week, which was to merge the AMR bank and the Penn treebank for a certain 100 sentences. This was because I did not have access to the data. The AMR data released by LDC was available to Columbia but is accessible only on the CCLS servers through a cs.columbia.edu account. I did not hear from Owen about accessing the data. 

End of Week Meeting Summary :

I started off asking Daniel why Owen had not replied. He told me that Owen had issued a support ticket to get me a cs.columbia.edu account but had not received a reply. Daniel got me the data from the CCLS servers inspite of that.
We had a look at the statistics and found several "low hanging fruit", as Daniel described it. These were very simple rules that could improve the accuracy by a huge margin. E.g. 
1. - , the polarity sign, was not aligned with words like "never", "without", "n't"
2. The concept 'you' went unaligned with "your". Also, whenever a verb was used imperatively, the concept 'you' was used, but went unaligned. e.g. "Please come with me" had the subgraph (come: imperative)..(you)...

We decided that we can try adding rules to the JAMR aligner and improve its accuracy, or use a hybrid approach which used statistical alignment based on the IBM models to identify cases missed by our rules (the USC ISI paper used the IBM model approach).
The todo for the next week was to run the JAMR aligner on the data that was used by the ISI people so as to get a direct comparison of the two methods. We would then decide how to progress. 
Daniel decided that he would do the pending task of creating the joint Penn treebank and AMR file, to give me time for the other task.
